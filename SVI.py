# -*- coding: utf-8 -*-
"""SVI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IYFjXSd9UNSceY3kZApWwLN3YMX9n1yp
"""

from math import *
from datetime import datetime
import numpy as np
import pandas as pd
import yfinance as yf
import matplotlib.pyplot as plt
from matplotlib.cm import ScalarMappable
from matplotlib.colors import Normalize
from scipy.stats import norm
from scipy.interpolate import interp1d, RBFInterpolator
from scipy.optimize import curve_fit, least_squares, brentq
from sklearn.isotonic import IsotonicRegression
from time import time

# ---------------------------------------------------------
# Simple module-level cache for per-(ticker, option_type) results
# ---------------------------------------------------------
_CACHE = {}  # key: (ticker, type) -> dict payload below
_CACHE_TTL_SECONDS = 15 * 60  # 15 minutes; tweak as you like

def _cache_key(ticker: str, option_type: str):
    return (ticker.upper(), option_type.lower())

def _is_fresh(entry) -> bool:
    if not entry: 
        return False
    ts = entry.get("timestamp", 0)
    return (time() - ts) < _CACHE_TTL_SECONDS

def _get_cached(ticker: str, option_type: str):
    return _CACHE.get(_cache_key(ticker, option_type))

def _set_cached(ticker: str, option_type: str, payload: dict):
    payload = dict(payload)
    payload["timestamp"] = time()
    _CACHE[_cache_key(ticker, option_type)] = payload



R = 0.05  # risk-free rate for discounting
THETA_PARAMS = None  # to cache a,b,c after first fit
W_PARAMS = None  # to cache rho,eta after first fit

def maturities_to_tj(date_str):
    """
    Converts a maturity date to time-to-maturity in years (ACT/365).
    Expiry is treated as end-of-day (23:59:59).

    Parameters:
        date_str (str): The maturity date in 'YYYY-MM-DD' format.
    Returns:
        float: Time to maturity in years.
    """
    today = datetime.today()
    maturity_date = datetime.strptime(date_str, '%Y-%m-%d').replace(
        hour=23, minute=59, second=59
    )
    delta = maturity_date - today
    tj = delta.total_seconds() / (365.0 * 24 * 3600)
    return tj

def prep(df,expiry):
    """
    Prepares the options DataFrame by calculating the mid price, adding expiration date,
    and computing time to maturity.
    Args:
        df: DataFrame from yfinance option chain (calls or puts).
        expiry: expiration date string 'YYYY-MM-DD'.
    Returns:
        DataFrame with added 'mid', 'expirationDate', and 'tj' columns.
    """
    df = df.copy()
    mid = (df['bid'].fillna(0) + df['ask'].fillna(0)) / 2
    need_fallback = (mid == 0) | mid.isna()
    mid.loc[need_fallback] = df.loc[need_fallback, 'lastPrice']
    df['mid'] = mid
    df['expirationDate'] = expiry
    df['tj'] = maturities_to_tj(expiry)
    return df

def compute_forwards(calls_df: pd.DataFrame, puts_df: pd.DataFrame, ticker_symbol: str, r: float, use_weights: bool = True):
    """
    Robust forward estimator per expiry using put-call parity across *many* strikes.

    Parity on forwards:  e^{rT}(C - P) = F - K  =>  F = K + e^{rT}(C - P).
    We estimate F_j for each expiry t_j by (optionally weighted) averaging K_i + e^{rT}(C_i - P_i)
    over all strikes common to calls & puts for that expiry.

    Args:
        calls_df, puts_df: dataframes from get_option_chain() (already have 'mid' and 'tj').
        ticker_symbol: for an ATM reference (weighting only).
        r: annual risk-free rate (continuously compounded).
        use_weights: if True, weight observations toward near-ATM strikes.

    Returns:
        forwards_df, calls_df_with_F, puts_df_with_F
    """

    # Spot only used to define "ATM-ish" weights (optional)
    spot = float(yf.Ticker(ticker_symbol).history(period='1d')['Close'].iloc[-1])

    expiries = sorted(set(calls_df['expirationDate']).intersection(set(puts_df['expirationDate'])))
    results = []

    # Pre-allocate F columns
    calls_df = calls_df.copy()
    puts_df  = puts_df.copy()
    calls_df['F'] = np.nan
    puts_df['F']  = np.nan

    for expiry in expiries:
        c_sub = calls_df[calls_df['expirationDate'] == expiry].copy()
        p_sub = puts_df[puts_df['expirationDate'] == expiry].copy()

        # Merge on common strikes
        merged = (c_sub[['strike','mid','tj']]
                  .merge(p_sub[['strike','mid']], on='strike', suffixes=('_c','_p')))

        if merged.empty:
            continue

        # Use the expiry's time-to-maturity
        T = float(merged['tj'].iloc[0])
        disc_inv = exp(r * T)          # e^{rT}
        y = disc_inv * (merged['mid_c'] - merged['mid_p'])  # ≈ F - K
        F_candidates = merged['strike'] + y                 # K + e^{rT}(C-P)

        # Optional: weight toward ATMish strikes for robustness
        if use_weights:
            # Distance from spot in log space is a decent proxy for vega shape
            k_abs = np.abs(np.log(np.maximum(1e-12, merged['strike'].values) / max(1e-12, spot)))
            # Smoothly cap extreme weights
            eps = 1e-3
            w = 1.0 / (k_abs + 0.10)  # slightly favors near-ATM without blowing up
        else:
            w = np.ones_like(F_candidates.values, dtype=float)

        # Weighted average forward for the expiry
        F_hat = float(np.average(F_candidates.values, weights=w))

        # Stash results and write F back into both frames for this expiry
        results.append({'expirationDate': expiry, 'tj': T, 'F': F_hat})
        calls_df.loc[calls_df['expirationDate'] == expiry, 'F'] = F_hat
        puts_df.loc[puts_df['expirationDate'] == expiry,  'F'] = F_hat

    forwards_df = pd.DataFrame(results).sort_values('tj').reset_index(drop=True)
    return forwards_df, calls_df, puts_df

def bs_price(k,w,tj,F,type_o):
    """
    Calculate the Black-Scholes price of an option.

    Parameters:
        option_row (pd.Series): A row from the options DataFrame containing necessary fields.
    Returns:
        float: The Black-Scholes price of the option. This is a simplified version assuming zero dividends and constant risk-free rate.
    """

    w = max(float(w), 1e-16)
    s = sqrt(w)
    d1 = (-k/s)+0.5*s
    d2 = d1 - s

    c = norm.cdf(d1) - exp(k) * norm.cdf(d2)
    p = exp(k) * norm.cdf(-d2) - norm.cdf(-d1)
    DF = exp(-R * tj)
    C = DF * F * c
    P = DF * F * p
    return C if type_o == 'call' else P

def clean_option_data(df):
    """
    Cleans the options DataFrame by removing rows with missing or invalid data.

    Parameters:
        df (pd.DataFrame): The options DataFrame to clean.
    Returns:
        pd.DataFrame: The cleaned options DataFrame.
    """
    df = df.copy()
    df = df.replace([np.inf, -np.inf], np.nan)
    df = df.dropna(subset=['strike', 'impliedVolatility', 'mid', 'tj', 'F'])
    df = df[df['impliedVolatility'] > 0]
    df = df[df['mid'] > 1e-3]
    df = df[df['ask'] >= df['bid']]
    df = df[df['tj'] > 0]
    df = df[df['F'] > 0]

    df = df.reset_index(drop=True)

    return df

def get_option_chain(ticker_symbol):
    """
    Fetches and returns the option chain for the given ticker symbol.

    Parameters:
        ticker_symbol (str): The stock ticker symbol.
    Returns:
        dict: A dictionary with 'calls' and 'puts' DataFrames.
    """

    ticker = yf.Ticker(ticker_symbol)
    expiries = ticker.options
    if not expiries:
        raise ValueError(f"No options data available for ticker symbol: {ticker_symbol}")
    all_calls = []
    all_puts = []

    for expiry in expiries:
        opt_chain = ticker.option_chain(expiry)
        calls = opt_chain.calls
        puts = opt_chain.puts

        all_calls.append(prep(calls, expiry))
        all_puts.append(prep(puts, expiry))

    all_calls_df = pd.concat(all_calls, ignore_index=True)
    all_puts_df = pd.concat(all_puts, ignore_index=True)

    calls_with_forwards = compute_forwards(all_calls_df, all_puts_df, ticker_symbol, r=R)
    all_calls_df = calls_with_forwards[1]
    all_puts_df = calls_with_forwards[2]

    # Log-moneyness
    all_calls_df['k'] = (all_calls_df['strike'] / all_calls_df['F']).apply(log)
    all_puts_df['k'] = (all_puts_df['strike'] / all_puts_df['F']).apply(log)

    # Total implied variance
    all_calls_df['w'] = (all_calls_df['impliedVolatility'] ** 2) * all_calls_df['tj']
    all_puts_df['w'] = (all_puts_df['impliedVolatility'] ** 2) * all_puts_df['tj']

    all_calls_df['type'] = 'call'
    all_puts_df['type'] = 'put'

    all_calls_df['bs_mid'] = all_calls_df.apply(lambda row: bs_price(row['k'], row['w'], row['tj'], row['F'], row['type']), axis=1)
    all_puts_df['bs_mid'] = all_puts_df.apply(lambda row: bs_price(row['k'], row['w'], row['tj'], row['F'], row['type']), axis=1)

    all_calls_df = clean_option_data(all_calls_df)
    all_puts_df = clean_option_data(all_puts_df)

    return {'calls': all_calls_df, 'puts': all_puts_df}

def theta_atm_for_expiry(ks, ws):
    """
    Estimate θ(t_j) = w(0,t_j) by weighted linear interpolation in (k,w) at k=0.
    ks, ws: numpy arrays of log-moneynesses and total variances for a single expiry t_j.
    Returns: float θ(t_j) or np.nan if no data.
    """
    ks = np.asarray(ks, dtype=float)
    ws = np.asarray(ws, dtype=float)
    m = np.isfinite(ks) & np.isfinite(ws)
    ks, ws = ks[m], ws[m]
    if ks.size == 0:
        return np.nan

    # Focus near k=0 (adaptive window, but not too wide)
    abs_k = np.abs(ks)
    target = min(0.25, float(np.percentile(abs_k, 40)) if abs_k.size else 0.25)
    mask = abs_k <= max(0.05, target)
    ks_win, ws_win = ks[mask], ws[mask]
    if ks_win.size < 3:
        mask = abs_k <= min(0.35, max(0.15, target*1.5))
        ks_win, ws_win = ks[mask], ws[mask]
    if ks_win.size < 2:
        # last resort: median of closest few
        order = np.argsort(abs_k)
        take = min(len(order), max(3, len(order)//3 or 1))
        return float(np.median(ws[order[:take]]))

    # Bracketing interpolation if we have k<0 and k>0
    k_below = ks_win[ks_win < 0]
    k_above = ks_win[ks_win > 0]
    if k_below.size and k_above.size:
        k1 = k_below.max()
        k2 = k_above.min()
        # pick exact matches
        w1 = ws_win[np.where(ks_win == k1)[0][0]]
        w2 = ws_win[np.where(ks_win == k2)[0][0]]
        return float(w1 + (0.0 - k1) * (w2 - w1) / (k2 - k1 + 1e-16))

    # Fallback: linear interp in (k,w)
    uniq_k, idxs = np.unique(ks_win, return_inverse=True)
    if uniq_k.size >= 2:
        if uniq_k.size != ks_win.size:
        # average w for duplicate ks
            w_acc = np.zeros_like(uniq_k, dtype=float)
            c_acc = np.zeros_like(uniq_k, dtype=int)
            for i, u in enumerate(idxs):
                w_acc[u] += ws_win[i]; c_acc[u] += 1
            ws_use = w_acc / np.maximum(c_acc, 1)
        else:
            ws_use = ws_win
        f = interp1d(uniq_k, ws_use, kind='linear', fill_value='extrapolate', assume_sorted=True)
        return float(f(0.0))

    # Last fallback
    return float(np.median(ws_win))

def build_theta(df):
    """
    Smooth ATM total variance curve θ(t) = w(0,t).
    Steps:
      1) For each expiry t, estimate θ_raw(t) via interpolation at k=0.
      2) Enforce monotone non-decreasing θ_iso(t) via isotonic regression.
      3) Fit smooth, monotone parametric curve θ(t) = a + b * t^c (a,b>=0, c>0),
         and return θ(t_j) evaluated at the listed expiries.

    Expects columns: ['tj','k','w']; optional ['bid','ask','mid'] for filtering.
    Returns: a, b, c
    """

    if not {'tj','k','w'}.issubset(df.columns):
        raise ValueError("DataFrame must contain 'tj','k','w'.")

    d = df.copy()
    d = d.replace([np.inf, -np.inf], np.nan).dropna(subset=['tj','k','w'])
    if 'ask' in d.columns and 'bid' in d.columns:
        d = d[(d['ask'] >= d['bid']).fillna(True)]
    if 'mid' in d.columns:
        d = d[(d['mid'] >= 1e-3).fillna(True)]

    # --- compute per-expiry θ_raw
    out = []
    for tj, g in d.groupby('tj'):
        g = g.sort_values('k')
        theta_raw = theta_atm_for_expiry(g['k'].to_numpy(), g['w'].to_numpy())
        out.append((float(tj), float(theta_raw)))
    thetas = pd.DataFrame(out, columns=['tj','theta_raw']).sort_values('tj').reset_index(drop=True)

    # --- enforce monotone non-decreasing via isotonic regression (no-arb baseline)
    ir = IsotonicRegression(increasing=True, out_of_bounds='clip')
    theta_iso = ir.fit_transform(thetas['tj'].to_numpy(float), thetas['theta_raw'].to_numpy(float))
    thetas['theta_iso'] = theta_iso

    # --- fit a smooth, monotone parametric curve θ(t) = a + b t^c with bounds
    def theta_model(t, a, b, c):
        t = np.asarray(t, dtype=float)
        t_pos = np.maximum(t, 1e-12)
        return a + b * (t_pos ** c)

    t_vals = thetas['tj'].to_numpy(float)
    y_vals = thetas['theta_iso'].to_numpy(float)

    # Initial guesses: a ≈ min θ, b ≈ (max-min), c ≈ 0.7 (concave-ish)
    a0 = max(0.0, float(np.nanmin(y_vals)))
    b0 = max(1e-8, float(np.nanmax(y_vals) - a0))
    c0 = 0.7

    try:
        popt, _ = curve_fit(theta_model, t_vals, y_vals,
                            p0=[a0, b0, c0],
                            bounds=([0.0, 0.0, 1e-3], [np.inf, np.inf, 2.0]),
                            maxfev=20000)
        theta_smooth = theta_model(t_vals, *popt)
    except Exception:
        # Fallback if optimizer struggles: just use θ_iso
        popt = (a0, b0, c0)
        theta_smooth = y_vals

    thetas['theta_smooth'] = theta_smooth

    return popt  # a, b, c

def theta_function(t, a, b, c):
    """
    Parametric θ(t) = a + b * t^c
    """
    return a + b * (t ** c)

def ssvi_sqrt(k, t, rho, eta, a, b, c):
    """
    SSVI total variance function w(k,t) = θ(t)/2 * (1 + ρφk + √((φk + ρ)^2 + (1 - ρ^2))
    where φ(t) = η / √θ(t), and θ(t) = a + b t^c.
    Args:
        k: log-moneyness (scalar or numpy array)
        t: time-to-maturity (scalar or numpy array)
        rho: correlation parameter (-1 < ρ < 1)
        eta: slope parameter (η > 0)
        a, b, c: parameters for θ(t)
    Returns:
        w: total implied variance (scalar or numpy array)
    """
    t = np.array(t)
    k = np.array(k)

    # Calculate theta(t) using vectorized operations
    theta_t = a + b * (t ** c)

    # Ensure theta_t is non-negative before taking the square root
    sqrt_theta = np.sqrt(np.maximum(theta_t, 1e-12))

    # Calculate phi(t)
    phi = eta / sqrt_theta

    # Use broadcasting for vectorized calculations
    term1 = 1.0 + rho * phi * k
    term2 = np.sqrt((phi * k + rho)**2 + (1 - rho**2))
    w = 0.5 * theta_t * (term1 + term2)

    return w

def bs_cost(r, F, k, t, rho, eta, a, b, c, type_o):
    """
    Function to calculate the Black-Scholes price
    using the SSVI total variance for calibration.
    Args:
        r: risk-free rate (annualized, continuously compounded)
        F: forward price
        k: log-moneyness
        t: time-to-maturity
        rho: correlation parameter (-1 < ρ < 1)
        eta: slope parameter (η > 0)
        a, b, c: parameters for θ(t)
        type_o: 'call' or 'put'
    Returns:
        price: Black-Scholes price using SSVI total variance
    """
    w = ssvi_sqrt(k, t, rho, eta, a, b, c)
    w = max(float(w), 1e-16)
    d1 = (-k/sqrt(w))+0.5*sqrt(w)
    d2 = (-k/sqrt(w))-0.5*sqrt(w)
    call_norm = norm.cdf(d1) - exp(k)*norm.cdf(d2)
    put_norm = exp(k)*norm.cdf(-d2) - norm.cdf(-d1)
    DF = exp(-r*t)
    Call = DF * F * call_norm
    Put = DF * F * put_norm
    return Call if type_o == 'call' else Put

def price_residuals(params, df):
    """
    Vectorized residuals function for least_squares fitting of (rho, eta).
    Uses global THETA_PARAMS = (a,b,c) for θ(t).
    Args:
        params: [rho, eta]
        df: DataFrame with at least ['k','tj','F','type','bs_mid']
    Returns:
        residuals: numpy array of model - market prices
    """
    if THETA_PARAMS is None:
        raise ValueError("THETA_PARAMS is not set. Call set_theta_params(a,b,c) first.")
    rho, eta = float(params[0]), float(params[1])
    a, b, c = THETA_PARAMS

    d = df[['k','tj','bs_mid','type','F']].replace([np.inf,-np.inf], np.nan).dropna()
    if d.empty:
        return np.zeros(0, dtype=float)

    ks  = d['k'].to_numpy(float)
    ts  = d['tj'].to_numpy(float)
    Fs  = d['F'].to_numpy(float)
    typ = d['type'].to_numpy(object)
    mkt = d['bs_mid'].to_numpy(float)

    # Vectorized evaluation via comprehension
    mdl = np.fromiter(
        (bs_cost(r=R, F=F, k=k, t=t, rho=rho, eta=eta, a=a, b=b, c=c, type_o=ty)
         for k,t,F,ty in zip(ks, ts, Fs, typ)),
        dtype=float, count=len(d)
    )
    return mdl - mkt

def first_guess(df, x0=None, bounds=None, max_nfev=500, verbose=0):
    """
    Fit only (rho, eta) with fixed θ(t) stored in THETA_PARAMS.
    Uses vectorized price_residuals(params, df) → residuals (model - market).

    Args:
        df        : DataFrame with at least ['k','tj','F','type','bs_mid']
        x0        : optional initial guess [rho, eta]
        bounds    : optional ([rho_lo, eta_lo], [rho_hi, eta_hi])
        max_nfev  : max function evaluations
        verbose   : scipy verbosity (0,1,2)

    Returns:
        (x_hat, res): best-fit [rho, eta] and the OptimizeResult
    """
    if THETA_PARAMS is None:
        raise ValueError("THETA_PARAMS is not set. Call set_theta_params(a,b,c) first.")

    if x0 is None:
        x0 = np.array([-0.50, 1.00], dtype=float)
    else:
        x0 = np.asarray(x0, dtype=float)

    if bounds is None:
        lb = np.array([-0.999, 1e-6], dtype=float)
        ub = np.array([ 0.999, 5.0  ], dtype=float)
        bounds = (lb, ub)

    # price_residuals is already vectorized; pass it directly
    res = least_squares(
        price_residuals,
        x0=x0,
        bounds=bounds,
        args=(df,),
        max_nfev=max_nfev,
        verbose=verbose
    )

    x_hat = res.x if res.success else x0
    return x_hat, res

def crossedness(params, df, num_points=200, delta_k=1, eps=1e-12, root_tol=1e-6):
    """
    Compute crossedness per maturity (Definition 5.1).
    First maturity's crossedness is defined as 0.0.

    Globals used:
      W_PARAMS = (rho, eta)
      THETA_PARAMS = (a, b, c)

    Returns:
      DataFrame with columns ['tj','crossedness'] where row j>0
      is Cross(t_{j-1}, t_j).
    """
    if THETA_PARAMS is None:
        raise ValueError("THETA_PARAMS must be set (a,b,c).")
    if 'tj' not in df.columns or 'k' not in df.columns:
        raise ValueError("df must contain 'tj' and 'k'.")

    rho, eta = float(params[0]), float(params[1])
    a, b, c = THETA_PARAMS

    # maturities
    t_unique = np.unique(df['tj'].to_numpy(float))
    t_unique.sort()
    if t_unique.size == 0:
        return pd.DataFrame(columns=['tj','crossedness'])

    # global k scan range (based on observed ks)
    k_obs = df['k'].to_numpy(float)
    k_min = float(np.nanmin(k_obs))
    k_max = float(np.nanmax(k_obs))

    out = [(float(t_unique[0]), 0.0)]  # first is defined as 0.0

    for idx in range(1, len(t_unique)):
        t1 = float(t_unique[idx - 1])
        t2 = float(t_unique[idx])

        # scan grid on the common observed range
        k_grid = np.linspace(k_min, k_max, num_points)

        # f(k) = w(t1,k) - w(t2,k)
        # ssvi_sqrt must accept vector k or broadcast via numpy
        f_vals = ssvi_sqrt(k_grid, t1, rho, eta, a, b, c) - ssvi_sqrt(k_grid, t2, rho, eta, a, b, c)
        f_vals = np.asarray(f_vals, dtype=float)
        f_vals[np.abs(f_vals) < eps] = 0.0  # treat tiny as zero

        # indices where sign changes between neighbors
        sign_prod = np.sign(f_vals[:-1]) * np.sign(f_vals[1:])
        brackets = np.where(sign_prod < 0)[0]
        zero_idx = np.where(f_vals == 0.0)[0]

        # collect roots: add exact-zero grid points, then refine brackets
        k_roots = []
        if zero_idx.size:
            k_roots.extend(k_grid[zero_idx].tolist())
        for j in brackets:
            a_k, b_k = k_grid[j], k_grid[j + 1]
            fa, fb = f_vals[j], f_vals[j + 1]
            try:
                # strict bracket only
                if fa * fb < 0.0:
                    r = brentq(
                        lambda kk: float(ssvi_sqrt(kk, t1, rho, eta, a, b, c) - ssvi_sqrt(kk, t2, rho, eta, a, b, c)),
                        a_k, b_k, maxiter=100
                    )
                    k_roots.append(float(r))
            except Exception:
                pass

        # deduplicate close roots
        if k_roots:
            k_roots = np.array(sorted(k_roots), dtype=float)
            merged = [k_roots[0]]
            for r in k_roots[1:]:
                if abs(r - merged[-1]) > root_tol:
                    merged.append(r)
            k_roots = np.array(merged, dtype=float)
        else:
            k_roots = np.array([], dtype=float)

        # Build mid-knots per Def. 5.1; clamp to [k_min,k_max]
        if k_roots.size >= 1:
            mid_knots = [max(k_min, min(k_max, k_roots[0] - delta_k))]
            for j in range(1, k_roots.size):
                mid_knots.append(0.5 * (k_roots[j - 1] + k_roots[j]))
            mid_knots.append(max(k_min, min(k_max, k_roots[-1] + delta_k)))
        else:
            # n=0 → crossedness is null; per definition, return 0 (no need to test ends)
            out.append((t2, 0.0))
            continue

        # c_i = max(0, w(t1,~k_i) - w(t2,~k_i)); crossedness = max_i c_i
        c_vals = []
        for kk in mid_knots:
            w1 = float(ssvi_sqrt(kk, t1, rho, eta, a, b, c))
            w2 = float(ssvi_sqrt(kk, t2, rho, eta, a, b, c))
            c_vals.append(max(0.0, w1 - w2))
        C = max(c_vals) if c_vals else 0.0

        out.append((t2, float(C)))

    return pd.DataFrame(out, columns=['tj','crossedness'])

def butterfly_residuals(params, df):
    """
    Vectorized residuals function for least_squares fitting of (rho, eta)
    to enforce the butterfly arbitrage constraints of Gatheral & Jacquier (2014).
    Uses global THETA_PARAMS = (a,b,c) for θ(t).
    Args:
        params: [rho, eta]
        df: DataFrame with at least ['tj']
    Returns:
        residuals: numpy array of [ (1+|ρ|) φ(t) - 4, (1+|ρ|) φ(t)^2 - 4 ] at the longest maturity
    """
    if THETA_PARAMS is None:
        raise ValueError("THETA_PARAMS is not set. Call set_theta_params(a,b,c) first.")
    rho, eta = float(params[0]), float(params[1])
    a, b, c = THETA_PARAMS
    tj = df['tj'].to_numpy(float)
    theta_t = a + b * (tj ** c)
    theta_max = float(np.max(theta_t))
    v1 = max(0.0, eta*eta * (1.0+abs(rho)) - 4.0)
    v2 = max(0.0, eta * sqrt(max(theta_max,1e-16)) * (1.0+abs(rho)) - 4.0)
    return np.array([v1, v2], dtype=float)

def net_residuals_per_slice(params, df, tj, scale_price=1.0, scale_butterfly=1.0, scale_calendar=1.0):
    """
    Combined residuals for a single maturity slice t_j:
      - price residuals for all options at t_j
      - butterfly arbitrage residuals at t_j
      - crossedness residual for slice t_j (0.0 if j=0)
    Args:
        params: [rho, eta]
        df: DataFrame with at least ['k','tj','F','type','bs_mid']
        tj: specific maturity to evaluate
    Returns:
        residuals: numpy array of concatenated residuals
    """
    d_slice = df[df['tj'] == tj]
    p_res = price_residuals(params, d_slice)
    b_res = butterfly_residuals(params, df)                  # shape (2,)
    c_res = crossedness(params, df)
    c_val = c_res[c_res['tj'] == tj]['crossedness'].to_numpy(float)
    c_vec = np.array([c_val[0] if c_val.size else 0.0], float)
    return np.concatenate([scale_price*p_res,
                       scale_butterfly*b_res,
                       scale_calendar*c_vec])

def slice_fit(df, tj, x0=None, bounds=None, max_nfev=1000, verbose=0):
    """
    Fit (rho, eta) for a single maturity slice t_j with fixed θ(t_j).
    Uses net_residuals_per_slice(params, df, tj) → residuals (model - market + arb).
    Args:
        df        : DataFrame with at least ['k','tj','F','type','bs_mid']
        x0        : optional initial guess [rho, eta]
        bounds    : optional ([rho_lo, eta_lo], [rho_hi, eta_hi])
        max_nfev  : max function evaluations
        verbose   : scipy verbosity (0,1,2)
    Returns:
        (x_hat, res): best-fit [rho, eta] and the OptimizeResult
    """
    if THETA_PARAMS is None:
        raise ValueError("THETA_PARAMS is not set. Call set_theta_params(a,b,c) first.")

    if x0 is None:
        x0 = np.array([-0.50, 1.00], dtype=float)
    else:
        x0 = np.asarray(x0, dtype=float)

    if bounds is None:
        lb = np.array([-0.999, 1e-6], dtype=float)
        ub = np.array([ 0.999, 5.0  ], dtype=float)
        bounds = (lb, ub)

    # net_residuals_per_slice is already vectorized; pass it directly
    res = least_squares(
        net_residuals_per_slice,
        x0=x0,
        bounds=bounds,
        args=(df, tj),
        max_nfev=max_nfev,
        verbose=verbose
    )

    x_hat = res.x if res.success else x0
    return x_hat, res

def plot_slice(df, tj, rho, eta, a, b, c, type_o='call', save=False):
    """
    Plot market vs model prices and implied volatilities for a single maturity slice t_j.
    Args:
        df: DataFrame with at least ['k','tj','F','type','bs_mid','impliedVolatility']
        tj: specific maturity to plot
        rho, eta: SSVI parameters for the slice
        a, b, c: parameters for θ(t)
        type_o: 'call' or 'put' to filter options
    Returns:
        None (displays plots)
    """
    d_slice = df[df['tj'] == tj]
    if d_slice.empty:
        print(f"No data for maturity tj={tj}")
        return
    ks = d_slice['k'].to_numpy(float)
    Fs = d_slice['F'].to_numpy(float)
    K = Fs * np.exp(ks)
    w_obs = d_slice['w'].to_numpy(float)
    w_est = ssvi_sqrt(ks, tj, rho, eta, a, b, c)
    bs_mid = d_slice['bs_mid'].to_numpy(float)
    bs_est = np.fromiter(
        (bs_cost(r=R, F=F, k=k, t=tj, rho=rho, eta=eta, a=a, b=b, c=c, type_o=ty)
         for k,F,ty in zip(ks, Fs, d_slice['type'].to_numpy(object))),
        dtype=float, count=len(d_slice)
    )

    # Subplot 1: Prices -> observed as points, model as line
    plt.figure(figsize=(12, 5))
    plt.subplot(1, 2, 1)
    plt.scatter(K, bs_mid, label='Market Price', color='blue', alpha=0.6)
    plt.plot(K, bs_mid, label='Market Price', color='blue', alpha=0.6)
    plt.scatter(K, bs_est, label='SSVI Model Price', color='red', alpha=0.6)
    plt.plot(K, bs_est, label='SSVI Model Price', color='red', alpha=0.6)
    plt.title(f"Option Prices at tj={tj:.4f} years")
    plt.xlabel("Strike Price K")
    plt.ylabel("Black-Scholes Price")
    plt.legend()
    plt.grid(True)

    # Subplot 2: Total Variance -> observed as points, model as line
    plt.subplot(1, 2, 2)
    plt.scatter(ks, w_obs, label='Market Total Variance', color='blue', alpha=0.6)
    plt.plot(ks, w_obs, label='Market Total Variance', color='blue', alpha=0.6)
    plt.scatter(ks, w_est, label='SSVI Model Total Variance', color='red', alpha=0.6)
    plt.plot(ks, w_est, label='SSVI Model Total Variance', color='red', alpha=0.6)
    plt.title(f"Total Implied Variance at tj={tj:.4f} years")
    plt.xlabel("Log-Moneyness k")
    plt.ylabel("Total Implied Variance w")
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    if save:
        fn = f"option_slice_tj{tj:.4f}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
        plt.savefig(fn, dpi=300)
        print(f"Saved option slice plot to {fn}")
    plt.show()

def all_slices(df, rho, eta, a, b, c, type_o='call', plot=True, save=False):
    """
    Get w(k,t) slices for all maturities in df using SSVI parameters.
    Args:
        df: DataFrame with at least ['k','tj','type']
        rho, eta: SSVI parameters
        a, b, c: parameters for θ(t)
        type_o: 'call' or 'put' to filter options
        plot: if True, plot the slices
        save: if True, save the plot to a file
    Returns:
        DataFrame with columns ['tj','k','w'] for the slices
    """
    d = df[df['type'] == type_o].copy()
    if d.empty:
        print(f"No data for option type '{type_o}'")
        return

    t_unique = np.unique(d['tj'].to_numpy(float))
    if t_unique.size == 0:
        print("No maturities found in data.")
        return

    k_all = d['k'].to_numpy(float)
    k_lo = np.percentile(k_all, 1)
    k_hi = np.percentile(k_all, 99)
    ks = np.linspace(k_lo, k_hi, 400)

    Wkt = []

    if plot:
        from matplotlib.colors import Normalize
        from matplotlib.cm import ScalarMappable
        fig, ax = plt.subplots(figsize=(10, 6))
        norm = Normalize(vmin=float(np.min(t_unique)), vmax=float(np.max(t_unique)))
        cmap = plt.cm.viridis

    for tj in sorted(t_unique):
        w_est = ssvi_sqrt(ks, tj, rho, eta, a, b, c)
        if plot:
            color = cmap(norm(tj))
            ax.plot(ks, w_est, color=color, linewidth=1.5)
        Wkt.extend(zip([tj]*len(ks), ks.tolist(), w_est.tolist()))

    if plot:
        ax.set_title(f"SSVI Total Implied Variance Slices ({type_o.capitalize()}s)")
        ax.set_xlabel("Log-Moneyness k")
        ax.set_ylabel("Total Implied Variance w")
        ax.grid(True)
        sm = ScalarMappable(norm=norm, cmap=cmap); sm.set_array([])
        cbar = fig.colorbar(sm, ax=ax); cbar.set_label('Maturity (years)')
        plt.tight_layout()
        if save:
            fn = f"w_slices_{type_o}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
            plt.savefig(fn, dpi=300)
            print(f"Saved w(k) slices plot to {fn}")
        plt.show()

    return pd.DataFrame(Wkt, columns=['tj','k','w'])

def plot_w_surface(Wkt, save=False):
    """
    Plot the w(k,t) surface using RBF interpolation for smoothing.
    Args:
        Wkt: DataFrame with columns ['tj','k','w']
        save: if True, save the plot to a file
    Returns:
        None (displays plot)
    """
    if Wkt.empty:
        print("No data to plot for w(k,t) surface.")
        return

    # data
    tj = Wkt['tj'].to_numpy(float)
    k  = Wkt['k'].to_numpy(float)
    w  = Wkt['w'].to_numpy(float)

    # (important) scale features so k and t have comparable units
    k_mu, k_sd = np.mean(k), np.std(k) or 1.0
    t_mu, t_sd = np.mean(tj), np.std(tj) or 1.0
    X = np.column_stack([(k - k_mu)/k_sd, (tj - t_mu)/t_sd])

    # grid
    tj_grid = np.linspace(np.min(tj), np.max(tj), 150)
    k_grid  = np.linspace(np.min(k),  np.max(k),  150)
    k_mesh, tj_mesh = np.meshgrid(k_grid, tj_grid)
    Xg = np.column_stack([(k_mesh.ravel()-k_mu)/k_sd, (tj_mesh.ravel()-t_mu)/t_sd])

    # RBF fit (try kernel='thin_plate_spline' or 'multiquadric')
    rbf = RBFInterpolator(X, w, kernel='thin_plate_spline', smoothing=1e-3)
    w_mesh = rbf(Xg).reshape(k_mesh.shape)

    # plot
    fig = plt.figure(figsize=(12, 8))
    ax  = fig.add_subplot(111, projection='3d')
    surf = ax.plot_surface(k_mesh, tj_mesh, w_mesh, cmap='viridis', edgecolor='none', alpha=0.9)
    ax.set_title('Total Implied Variance Surface w(k,t) — RBF smoothed')
    ax.set_xlabel('Log-Moneyness k')
    ax.set_ylabel('Maturity t (years)')
    ax.set_zlabel('Total Implied Variance w')
    fig.colorbar(surf, ax=ax, shrink=0.5, aspect=6)
    if save:
        fn = f"w_surface_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
        plt.savefig(fn, dpi=300)
        print(f"Saved w(k,t) surface plot to {fn}")
    plt.show()

def sigma_atm(t, a, b, c):
    """
    ATM implied volatility σ(0,t) = √(θ(t)/t)
    """
    theta_t = a + b * (t ** c)
    return np.sqrt(np.maximum(theta_t / t, 0.0))


def tj_to_maturities(tj_array, ref_date=None):
    """
    Convert time-to-expiry in years (tj) back to actual maturity dates.

    Args:
        tj_array: list or np.ndarray of time-to-expiry in years
        ref_date: reference date (datetime or str 'YYYY-MM-DD').
                  Defaults to today's date if None.

    Returns:
        maturities: list of pandas.Timestamp objects
    """
    if ref_date is None:
        ref_date = datetime.today()
    elif isinstance(ref_date, str):
        ref_date = pd.Timestamp(ref_date)

    maturities = [ref_date + pd.Timedelta(days=float(tj) * 365.0) for tj in tj_array]
    return maturities

def get_theta_fit(ticker_symbol: str, type: str) -> dict:
    """
    Wrapper to compute θ(t) = a + b * t^c for a given ticker symbol.

    Returns:
        {
            'a': float,
            'b': float,
            'c': float,
            'tj': np.ndarray,        # maturities (years)
            'theta': np.ndarray      # theta(tj) values
        }
    """
    # 1) Load option data
    chain = get_option_chain(ticker_symbol)
    calls = chain['calls']
    puts = chain['puts']
    all_options = pd.concat([calls, puts], ignore_index=True)

    if type == 'call':
        all_options = all_options[all_options['type'] == 'call']
    elif type == 'put':
        all_options = all_options[all_options['type'] == 'put']
    elif type != 'both':
        raise ValueError("type must be 'call', 'put', or 'both'")

    # 2) Fit theta(t) = a + b * t^c
    a, b, c = build_theta(all_options)
    tj = np.sort(all_options['tj'].unique())
    theta_vals = a + b * (tj ** c)

    # 3) Package neatly
    result = {
        "a": float(a),
        "b": float(b),
        "c": float(c),
        "tj": tj.tolist(),
        "maturities": tj_to_maturities(tj),
        "theta": theta_vals.tolist()
    }
    return result

def get_slices_df(ticker_symbol: str, verbose: int = 0) -> pd.DataFrame:
    """
    Convenience wrapper:
      1) fetch complete option chain for `ticker_symbol`
      2) fit θ(t) = a + b t^c and set global THETA_PARAMS
      3) get a global first-guess (rho, eta)
      4) fit (rho, eta) slice-by-slice to build `slices_df`

    Returns:
        slices_df : DataFrame with columns ['tj', 'rho', 'eta'], sorted by tj
    """
    # 1) Pull options and assemble the working frame
    chain = get_option_chain(ticker_symbol)
    calls = chain['calls']
    puts  = chain['puts']
    all_options = pd.concat([calls, puts], ignore_index=True)

    # 2) Fit theta(t) and cache
    a, b, c = build_theta(all_options)
    global THETA_PARAMS, W_PARAMS
    THETA_PARAMS = (a, b, c)

    # 3) First-guess across all points to seed per-slice fits
    (rho_hat, eta_hat), _ = first_guess(all_options, x0=[-0.5, 1.0], verbose=verbose)
    W_PARAMS = (rho_hat, eta_hat)

    # 4) Slice-by-slice fit
    ts = sorted(all_options['tj'].unique())
    rows = []
    for tj in ts:
        (rho_j, eta_j), _ = slice_fit(all_options, tj, x0=[rho_hat, eta_hat], verbose=verbose)
        rows.append((float(tj), float(rho_j), float(eta_j)))

    slices_df = pd.DataFrame(rows, columns=['tj', 'rho', 'eta']).sort_values('tj').reset_index(drop=True)
    return slices_df, a, b, c


def get_slice_xy_for_ticker(ticker_symbol: str,
                            tj_value: float,
                            type_o: str = 'call',
                            verbose: int = 0):
    """
    Return arrays to plot one SSVI slice (market vs model) for a given ticker and tj.

    Returns:
        {
          'ticker': str,
          'requested_tj': float,     # what you asked for
          'chosen_tj': float,        # nearest maturity actually used
          'a': float, 'b': float, 'c': float,
          'rho': float, 'eta': float,
          'k_market': np.ndarray,
          'w_market': np.ndarray,
          'k_model': np.ndarray,
          'w_model': np.ndarray
        }
    """
    # ----- Guard & normalize inputs
    if tj_value is None:
        raise ValueError("tj_value is None. Pass a float time-to-maturity in years.")
    try:
        tj_req = float(tj_value)
    except Exception:
        raise ValueError(f"tj_value='{tj_value}' is not a float.")

    # ----- 1) Pull option chain & combine
    chain = get_option_chain(ticker_symbol)   # calls/puts dataframes
    df = pd.concat([chain['calls'], chain['puts']], ignore_index=True)

    # Ensure 'tj' is numeric and drop invalid rows
    df = df.copy()
    df['tj'] = pd.to_numeric(df['tj'], errors='coerce')
    df = df.dropna(subset=['tj', 'k', 'w'])
    if df.empty:
        raise ValueError("No valid option rows after cleaning.")

    # ----- 2) Fit θ(t) = a + b t^c and cache
    a, b, c = build_theta(df)                 # fits params for theta(t)
    global THETA_PARAMS
    THETA_PARAMS = (a, b, c)

    # ----- 3) First-guess (ρ, η) and then slice-refine at nearest maturity
    (rho_hat, eta_hat), _ = first_guess(df, x0=[-0.5, 1.0], verbose=verbose)

    # pick the closest available maturity to requested tj
    tjs_available = np.sort(df['tj'].to_numpy(dtype=float))
    if tjs_available.size == 0:
        raise ValueError("No maturities found in option data.")
    chosen_tj = float(tjs_available[np.argmin(np.abs(tjs_available - tj_req))])

    (rho_j, eta_j), _ = slice_fit(df, chosen_tj, x0=[rho_hat, eta_hat], verbose=verbose)

    # ----- 4) Extract market slice for requested option type
    d_slice = df[(df['type'] == type_o) & (np.isclose(df['tj'], chosen_tj, atol=1e-12))].copy()
    if d_slice.empty:
        # fallback: ignore type filter if no rows (e.g., only calls/puts exist)
        d_slice = df[np.isclose(df['tj'], chosen_tj, atol=1e-12)].copy()
    if d_slice.empty:
        raise ValueError(f"No rows for chosen maturity tj={chosen_tj:.6f}.")

    k_market = d_slice['k'].to_numpy(dtype=float)
    w_market = d_slice['w'].to_numpy(dtype=float)

    # ensure k range is sane
    k_min, k_max = float(np.min(k_market)), float(np.max(k_market))
    if not np.isfinite(k_min) or not np.isfinite(k_max) or k_min == k_max:
        # widen a tiny bit if degenerate
        k_min, k_max = k_min - 0.05, k_max + 0.05

    # ----- 5) Smooth model curve
    k_model = np.linspace(k_min, k_max, 200)
    w_model = ssvi_sqrt(k_model, chosen_tj, rho_j, eta_j, a, b, c)

    if verbose:
        print(f"θ(t) = {a:.6f} + {b:.6f} * t^{c:.6f}")
        print(f"requested tj={tj_req:.6f}  → chosen tj={chosen_tj:.6f}")
        print(f"slice params: ρ={rho_j:.4f}, η={eta_j:.4f}")

    return {
        "ticker": ticker_symbol,
        "requested_tj": tj_req,
        "chosen_tj": chosen_tj,
        "a": float(a), "b": float(b), "c": float(c),
        "rho": float(rho_j), "eta": float(eta_j),
        "k_market": k_market,
        "w_market": w_market,
        "k_model": k_model,
        "w_model": w_model
    }

def get_slice_xy_full_for_ticker(ticker_symbol: str,
                                 tj_value: float,
                                 type_filter: str = 'all',   # 'all' | 'call' | 'put'
                                 verbose: int = 0,
                                 json_safe: bool = True):
    """
    Returns data needed to reproduce the original two-panel plot:

      Panel A (Prices vs Strike K):
        - K_market: strikes (from F * exp(k))
        - price_market: market BS price (your 'bs_mid')
        - price_model: SSVI-implied BS price via bs_cost

      Panel B (Total variance w vs log-moneyness k):
        - k_market: observed k
        - w_market: observed total variance w
        - w_model_at_market_k: model w at same ks
        - k_curve / w_model_curve: smooth curve for drawing a line

    Also returns fitted params and the chosen maturity (closest to request).

    json_safe=True converts arrays to lists and numpy scalars to Python scalars.
    """
    # --- Validate tj input
    if tj_value is None:
        raise ValueError("tj_value is None. Pass a float time-to-maturity (years).")
    try:
        tj_req = float(tj_value)
    except Exception:
        raise ValueError(f"tj_value='{tj_value}' is not a float.")

    # --- 1) Pull and combine option data
    chain = get_option_chain(ticker_symbol)  # {'calls': DataFrame, 'puts': DataFrame}
    df = pd.concat([chain['calls'], chain['puts']], ignore_index=True)

    # Coerce and clean core columns used below
    df = df.copy()
    df['tj'] = pd.to_numeric(df['tj'], errors='coerce')
    df['k']  = pd.to_numeric(df['k'],  errors='coerce')
    df['w']  = pd.to_numeric(df['w'],  errors='coerce')
    df['F']  = pd.to_numeric(df['F'],  errors='coerce')
    df['bs_mid'] = pd.to_numeric(df['bs_mid'], errors='coerce')
    df = df.dropna(subset=['tj','k','w','F','bs_mid'])
    if df.empty:
        raise ValueError("No valid option rows after cleaning.")

    # Optional filter by type
    if type_filter in ('call','put'):
        df = df[df['type'] == type_filter]
        if df.empty:
            raise ValueError(f"No rows for option type '{type_filter}' after cleaning.")

    # --- 2) Fit theta(t) = a + b t^c
    a, b, c = build_theta(df)
    global THETA_PARAMS
    THETA_PARAMS = (a, b, c)

    # --- 3) First-guess (rho, eta) globally, then refine for chosen slice
    (rho_hat, eta_hat), _ = first_guess(df, x0=[-0.5, 1.0], verbose=verbose)

    # Pick closest available maturity to requested tj
    tjs_available = np.sort(df['tj'].to_numpy(dtype=float))
    chosen_tj = float(tjs_available[np.argmin(np.abs(tjs_available - tj_req))])

    (rho_j, eta_j), _ = slice_fit(df, chosen_tj, x0=[rho_hat, eta_hat], verbose=verbose)

    # --- 4) Slice rows at chosen_tj (don’t filter by type here to mirror plot_slice)
    d_slice = df[np.isclose(df['tj'], chosen_tj, atol=1e-12)].copy()
    if d_slice.empty:
        raise ValueError(f"No rows for chosen maturity tj={chosen_tj:.6f}.")

    # Panel B (variance): observed and model at market ks
    ks = d_slice['k'].to_numpy(float)
    w_market = d_slice['w'].to_numpy(float)
    w_model_at_market_k = ssvi_sqrt(ks, chosen_tj, rho_j, eta_j, a, b, c)  # like in plot_slice
    # Smooth curve for a nice line
    k_min, k_max = float(np.min(ks)), float(np.max(ks))
    if not np.isfinite(k_min) or not np.isfinite(k_max) or k_min == k_max:
        k_min, k_max = k_min - 0.05, k_max + 0.05
    k_curve = np.linspace(k_min, k_max, 200)
    w_model_curve = ssvi_sqrt(k_curve, chosen_tj, rho_j, eta_j, a, b, c)

    # Panel A (prices): BS market vs model, against strike K
    Fs = d_slice['F'].to_numpy(float)
    K_market = Fs * np.exp(ks)
    price_market = d_slice['bs_mid'].to_numpy(float)  # exactly as in your plot_slice
    price_model = np.fromiter(
        (bs_cost(r=R, F=F, k=k, t=chosen_tj, rho=rho_j, eta=eta_j, a=a, b=b, c=c, type_o=ty)
         for k, F, ty in zip(ks, Fs, d_slice['type'].to_numpy(object))),
        dtype=float, count=len(d_slice)
    )

    theta_t = a + b * (chosen_tj ** c)

    out = {
        "ticker": ticker_symbol,
        "requested_tj": float(tj_req),
        "chosen_tj": float(chosen_tj),
        "theta_t": float(theta_t),
        "params": {"a": float(a), "b": float(b), "c": float(c), "rho": float(rho_j), "eta": float(eta_j)},
        "panel_prices": {
            "K_market": K_market,
            "price_market": price_market,
            "price_model": price_model
        },
        "panel_variance": {
            "k_market": ks,
            "w_market": w_market,
            "w_model_at_market_k": w_model_at_market_k,
            "k_curve": k_curve,
            "w_model_curve": w_model_curve
        }
    }

    if not json_safe:
        return out

    # JSON-safe conversion (arrays → lists, numpy scalars → Python scalars)
    def J(x):
        if isinstance(x, np.ndarray): return x.tolist()
        if isinstance(x, (np.floating, np.integer, np.bool_)): return x.item()
        if isinstance(x, dict): return {k: J(v) for k, v in x.items()}
        if isinstance(x, (list, tuple)): return [J(v) for v in x]
        return x

    return J(out)


def get_all_slices_df(ticker_symbol: str,
                      type_o: str = 'call',
                      verbose: int = 0,
                      as_json: bool = True,
                      refresh: bool = False):
    """
    Warms cache for (ticker, type_o) and returns the same structure as before.
    """
    # Try cache unless refresh requested
    cached = _get_cached(ticker_symbol, type_o)
    if (not refresh) and _is_fresh(cached) and ("slices_df" in cached):
        out = {
            "ticker": ticker_symbol,
            "a": float(cached["a"]), "b": float(cached["b"]), "c": float(cached["c"]),
            "rho": float(cached["rho"]), "eta": float(cached["eta"]),
            "slices_df": cached["slices_df"]
        }
        if not as_json:
            return out
        # JSON-safe convert (same as old)
        def _js(x):
            if isinstance(x, np.ndarray): return x.tolist()
            if isinstance(x, (np.floating, np.integer, np.bool_)): return x.item()
            if isinstance(x, pd.DataFrame): return x.to_dict(orient="records")
            if isinstance(x, pd.Series): return x.to_list()
            if isinstance(x, dict): return {k: _js(v) for k, v in x.items()}
            if isinstance(x, (list, tuple)): return [_js(v) for v in x]
            return x
        return _js(out)

    # Build fresh
    chain = get_option_chain(ticker_symbol)
    df = pd.concat([chain['calls'], chain['puts']], ignore_index=True)

    a, b, c = build_theta(df)
    global THETA_PARAMS
    THETA_PARAMS = (a, b, c)

    (rho_hat, eta_hat), _ = first_guess(df, x0=[-0.5, 1.0], verbose=verbose)

    # compute all slices *and* remember per-slice params
    tjs = sorted(df['tj'].unique())
    slice_params = {}
    rows = []
    for tj in tjs:
        (rho_j, eta_j), _ = slice_fit(df, tj, x0=[rho_hat, eta_hat], verbose=verbose)
        slice_params[float(tj)] = (float(rho_j), float(eta_j))
        rows.append((float(tj), float(rho_j), float(eta_j)))
    slices_df_params = pd.DataFrame(rows, columns=['tj','rho','eta']).sort_values('tj').reset_index(drop=True)

    # Then produce the w(k,t) grid (unchanged behavior)
    slices_df = all_slices(df, rho_hat, eta_hat, a, b, c, type_o=type_o, plot=False, save=False)

    # Warm the cache
    _set_cached(ticker_symbol, type_o, {
        "df": df,                 # combined calls+puts with F, k, w, bs_mid, tj
        "a": float(a), "b": float(b), "c": float(c),
        "rho": float(rho_hat), "eta": float(eta_hat),
        "tjs": np.array(tjs, dtype=float),
        "slice_params": slice_params,   # dict[tj] -> (rho_j, eta_j)
        "slices_df": slices_df          # ready-to-serve DataFrame for surface
    })

    out = {
        "ticker": ticker_symbol,
        "a": float(a), "b": float(b), "c": float(c),
        "rho": float(rho_hat), "eta": float(eta_hat),
        "slices_df": slices_df
    }

    if not as_json:
        return out

    def _js(x):
        if isinstance(x, np.ndarray): return x.tolist()
        if isinstance(x, (np.floating, np.integer, np.bool_)): return x.item()
        if isinstance(x, pd.DataFrame): return x.to_dict(orient="records")
        if isinstance(x, pd.Series): return x.to_list()
        if isinstance(x, dict): return {k: _js(v) for k, v in x.items()}
        if isinstance(x, (list, tuple)): return [_js(v) for v in x]
        return x

    return _js(out)

def get_plot_slice_arrays(ticker_symbol: str, tj_value: float, option_type: str = "call"):
    """
    Returns (K, k, bs_mid, bs_est, w_obs, w_est) for the slice nearest to tj_value,
    now optimized to reuse cache warmed by get_all_slices_df().
    """
    if option_type not in ("call", "put"):
        raise ValueError("option_type must be 'call' or 'put'")
    try:
        tj_req = float(tj_value)
    except Exception:
        raise ValueError(f"tj_value='{tj_value}' is not a float.")

    cached = _get_cached(ticker_symbol, option_type)
    if not _is_fresh(cached):
        # Fallback: warm the cache quickly without JSON conversion
        get_all_slices_df(ticker_symbol, option_type, as_json=False)

    cached = _get_cached(ticker_symbol, option_type)
    if not cached:
        raise RuntimeError("Cache initialization failed.")

    df   = cached["df"]
    a,b,c = cached["a"], cached["b"], cached["c"]

    # choose nearest tj present in df for this option type
    df_type = df[df["type"] == option_type].copy()
    df_type = df_type.dropna(subset=["tj","k","w","F","bs_mid"])
    if df_type.empty:
        raise ValueError(f"No {option_type}s available after cleaning.")
    tjs = np.sort(df_type["tj"].to_numpy(float))
    chosen_tj = float(tjs[np.argmin(np.abs(tjs - tj_req))])

    # per-slice params: use cache or fit once and store
    slice_params = cached.get("slice_params", {})
    if chosen_tj in slice_params:
        rho_j, eta_j = slice_params[chosen_tj]
    else:
        # light one-off refinement for this exact slice
        global THETA_PARAMS
        THETA_PARAMS = (a,b,c)
        (rho_hat, eta_hat) = (cached["rho"], cached["eta"])
        (rho_j, eta_j), _ = slice_fit(df, chosen_tj, x0=[rho_hat, eta_hat], verbose=0)
        # update cache in place
        slice_params[chosen_tj] = (float(rho_j), float(eta_j))
        _set_cached(ticker_symbol, option_type, {**cached, "slice_params": slice_params})

    # Now extract arrays for this slice & type
    d = df_type[np.isclose(df_type["tj"], chosen_tj, atol=1e-12)].copy()
    if d.empty:
        raise ValueError(f"No rows for chosen maturity tj={chosen_tj:.6f}.")

    ks = d["k"].to_numpy(float)      # k
    Fs = d["F"].to_numpy(float)
    K  = Fs * np.exp(ks)             # K
    w_obs = d["w"].to_numpy(float)   # w_obs
    w_est = ssvi_sqrt(ks, chosen_tj, rho_j, eta_j, a, b, c)  # w_est
    bs_mid = d["bs_mid"].to_numpy(float)                     # bs_mid
    bs_est = np.fromiter(
        (bs_cost(r=R, F=F, k=k, t=chosen_tj, rho=rho_j, eta=eta_j, a=a, b=b, c=c, type_o=option_type)
         for k, F in zip(ks, Fs)),
        dtype=float, count=len(d)
    )  # bs_est

    return K, ks, bs_mid, bs_est, w_obs, w_est



if __name__ == "__main__":
    ticker_symbol = 'AAPL'


    calls_and_puts = get_option_chain(ticker_symbol)
    calls = calls_and_puts['calls']
    puts = calls_and_puts['puts']

    all_options = pd.concat([calls, puts], ignore_index=True)


    a, b, c = build_theta(all_options)
    THETA_PARAMS = (a, b, c)
    print(f"Fitted theta params: a={a:.6f}, b={b:.6f}, c={c:.6f}")


    initial_guess = [-0.5, 1.0]
    (rho_hat, eta_hat), result = first_guess(all_options, x0=initial_guess, verbose=0)
    print(f"Fitted SSVI params (first guess): rho={rho_hat:.6f}, eta={eta_hat:.6f}")
    W_PARAMS = (rho_hat, eta_hat)


    t = sorted(all_options['tj'].unique())

    slice_results = []

    for tj in t:
        (rho_j, eta_j), res_j = slice_fit(all_options, tj, x0=[rho_hat, eta_hat], verbose=0)
        slice_results.append((tj, rho_j, eta_j))

    slices_df = pd.DataFrame(slice_results, columns=['tj','rho','eta'])
    print(slices_df)


    plot_individual_slices_bool = False


    save_individual_slices_bool = False

    if plot_individual_slices_bool:
        for idx, row in slices_df.iterrows():
            tj, rho_j, eta_j = row['tj'], row['rho'], row['eta']
            print(f"Plotting slice for tj={tj:.4f}, rho={rho_j:.6f}, eta={eta_j:.6f}")
            plot_slice(all_options, tj, rho_j, eta_j, a, b, c, type_o='call', save=save_individual_slices_bool)


    plot_all_slices_bool = True


    save_all_slices_bool = False

    Wkt = all_slices(all_options, rho_hat, eta_hat, a, b, c, type_o='call', plot=plot_all_slices_bool, save=save_all_slices_bool)

    
    plot_surface_bool = True


    save_surface_bool = False

    if plot_surface_bool:
        plot_w_surface(Wkt, save=save_surface_bool)